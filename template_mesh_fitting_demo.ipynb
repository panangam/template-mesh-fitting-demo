{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123d4266",
   "metadata": {},
   "source": [
    "# Template Mesh Fitting Demo\n",
    "\n",
    "For Tesla virtual onsite interview presentation.\n",
    "\n",
    "The notebook will walk through the process of fitting a template mesh onto a target mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154c2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from star.pytorch.star import STAR\n",
    "from star.config import set_model_path\n",
    "import vedo\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da124307",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_model_path('star_1_1')\n",
    "vedo.embedWindow('k3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a234ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmesh(mesh, c='grey', alpha=0.5):\n",
    "    \"\"\"convenience function for transparent mesh\"\"\"\n",
    "    return vedo.Mesh(mesh, c=c, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f5e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mesh = trimesh.load_mesh('ORPH_20200122_2354_healed.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34f67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_betas = 20\n",
    "star = STAR(gender='neutral', num_betas=num_betas)\n",
    "\n",
    "A_pose_np = np.zeros((1, 72))\n",
    "A_pose_np[0, 3*1+2] = 0.2\n",
    "A_pose_np[0, 3*2+2] = -0.2\n",
    "A_pose_np[0, 3*13+2] = -0.2\n",
    "A_pose_np[0, 3*14+2] = 0.2\n",
    "A_pose_np[0, 3*16+2] = -0.8\n",
    "A_pose_np[0, 3*17+2] = 0.8\n",
    "A_pose = torch.tensor(A_pose_np)\n",
    "\n",
    "betas = torch.tensor(np.zeros((1, num_betas)))\n",
    "trans = torch.tensor(np.zeros((1, 3)))\n",
    "\n",
    "template_verts = np.roll(star.forward(A_pose, betas, trans)[0], 1, axis=1) * 1000\n",
    "non_aligned_template_mesh = trimesh.Trimesh(template_verts, star.f, process=False)\n",
    "\n",
    "# centroid align\n",
    "trans_align_np = np.roll(\n",
    "    target_mesh.vertices.mean(axis=0) - non_aligned_template_mesh.vertices.mean(axis=0), \n",
    "    -1\n",
    ") / 1000\n",
    "trans_align = torch.tensor(trans_align_np[None, :])\n",
    "align_template_verts = np.roll(star.forward(A_pose, betas, trans_align)[0], 1, axis=1) * 1000\n",
    "template_mesh = trimesh.Trimesh(align_template_verts, star.f, process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb4cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vertex_groups.json') as fin:\n",
    "    vertex_groups = json.load(fin)\n",
    "exclude_idx = [i for name in ('head', 'hand_left', 'hand_right', 'toes') for i in vertex_groups[name]]\n",
    "inc_verts = np.ones(template_mesh.vertices.shape[0], dtype=bool)\n",
    "inc_verts[exclude_idx] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd78883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_heels(mesh):\n",
    "    v = mesh.vertices\n",
    "    mid_y = (v[:, 1].max()+v[:, 1].min())/2\n",
    "    left_idx, = (v[:, 1] > mid_y).nonzero()\n",
    "    left_heel_idx = left_idx[(v[left_idx, 0]+v[left_idx, 2]).argmin()]\n",
    "    right_idx, = (v[:, 1] < mid_y).nonzero()\n",
    "    right_heel_idx = right_idx[(v[right_idx, 0]+v[right_idx, 2]).argmin()]\n",
    "    \n",
    "    return left_heel_idx, right_heel_idx\n",
    "\n",
    "# find template heels\n",
    "template_left_heel_idx, template_right_heel_idx = find_heels(template_mesh)\n",
    "\n",
    "# find target heels\n",
    "target_left_heel, target_right_heel = target_mesh.vertices[find_heels(target_mesh), :]\n",
    "\n",
    "landmarks = [(template_left_heel_idx, target_left_heel), (template_right_heel_idx, target_right_heel)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d47ac5",
   "metadata": {},
   "source": [
    "Plot below shows the template mesh. The vertices that are excluded from fitting are highlighted in red. Heels are highlighted in blue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe153eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009e09550aa646a582fbe886d1f84b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera=[1140.0429027815971…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vedo.show(\n",
    "    template_mesh,\n",
    "    vedo.Spheres(template_mesh.vertices[exclude_idx], r=10),\n",
    "    vedo.Spheres(template_mesh.vertices[[template_left_heel_idx, template_right_heel_idx]], r=20, c='blue'),\n",
    "    viewup='z',\n",
    "    axes=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9f1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrow_plot(template_mesh, target_mesh, inc_verts):\n",
    "    template_verts = template_mesh.vertices[inc_verts]\n",
    "    dists, idxs = target_mesh.kdtree.query(template_verts)\n",
    "    arrows = vedo.Arrows(template_verts, target_mesh.vertices[idxs])\n",
    "    return vedo.show(\n",
    "        tmesh(template_mesh),\n",
    "        tmesh(target_mesh), \n",
    "        arrows,\n",
    "        viewup='z'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774bb90",
   "metadata": {},
   "source": [
    "### Diff plot: before fit\n",
    "\n",
    "The arrows point from a template vertex to the closest target vertex, which are the pairs used to calculate data loss. The optimizer will try to deform the vertices in the arrows direction, thus matching the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba56729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69ee0a3fd354a669392a98e78582d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera=[1120.2648393608604…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arrow_plot(template_mesh, target_mesh, inc_verts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4dee5",
   "metadata": {},
   "source": [
    "### Define the loss functions\n",
    "\n",
    "We have\n",
    "\n",
    "- data loss: the ICP sum of squared distances between corresponding vertices\n",
    "- marking loss: sum of squared distances between markings\n",
    "- regularization loss: try to keep the shape parameters close to mean shape so things don't go crazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b17b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"define loss functions\"\"\"\n",
    "def calc_loss(\n",
    "    deformed_v: torch.Tensor, \n",
    "    betas: torch.Tensor, \n",
    "    exc_verts=[], min_comp_cosine=0, landmarks=[], E_weights=(1, 1, 0)\n",
    "):\n",
    "    E_data = data_loss(deformed_v, target_mesh, exc_verts, min_comp_cosine)\n",
    "    E_lm = landmark_loss(deformed_v, landmarks)\n",
    "    E_reg = shape_reg_loss(betas)\n",
    "#     breakpoint()\n",
    "    \n",
    "    E_total = E_weights[0]*E_data + E_weights[1]*E_lm + E_weights[2]*E_reg\n",
    "    \n",
    "    return E_total\n",
    "\n",
    "def data_loss(deformed_v : torch.Tensor, target_mesh, exc_verts, min_comp_cosine):\n",
    "    deformed_mesh = trimesh.Trimesh(deformed_v.detach().numpy(), star.f, process=False)\n",
    "    dists, idxs = target_mesh.kdtree.query(deformed_mesh.vertices)\n",
    "    deformed_normals = deformed_mesh.vertex_normals\n",
    "    target_normals = target_mesh.vertex_normals\n",
    "    incompatible = (target_normals[idxs]*deformed_normals).sum(axis=1) < min_comp_cosine\n",
    "    weights = np.ones(template_mesh.vertices.shape[0])\n",
    "    weights[incompatible] = 0\n",
    "    weights[exc_verts] = 0\n",
    "\n",
    "    dist_tensor = (\n",
    "        (\n",
    "            (\n",
    "                deformed_v-torch.tensor(target_mesh.vertices[idxs], requires_grad=False)\n",
    "            ) * torch.tensor(weights[:, None], requires_grad=False)\n",
    "        )**2\n",
    "    ).sum() / weights.sum()\n",
    "    return dist_tensor\n",
    "\n",
    "def landmark_loss(deformed_v: torch.Tensor, landmarks):\n",
    "    loss = torch.tensor(0.)\n",
    "    for template_idx, target in landmarks:\n",
    "        loss += ((deformed_v[template_idx] - torch.tensor(target))**2).sum()\n",
    "    if len(landmarks) > 0:\n",
    "        loss /= len(landmarks)\n",
    "    return loss\n",
    "\n",
    "def shape_reg_loss(betas: torch.Tensor):\n",
    "    return (betas**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345876f",
   "metadata": {},
   "source": [
    "## Perform the fitting!\n",
    "\n",
    "Using PyTorch's `LBFGS` built-in optimizer for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2022c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import LBFGS\n",
    "\n",
    "poses = torch.tensor(A_pose_np, requires_grad=True)\n",
    "betas = torch.tensor(np.random.normal(0, 0, (1, num_betas)), requires_grad=True)\n",
    "trans = torch.tensor(trans_align_np[None, :], requires_grad=True)\n",
    "\n",
    "optimizer = LBFGS([poses, betas, trans], lr=1, max_iter=100)\n",
    "\n",
    "def simple_loss(poses, betas, trans, min_comp_cosine, E_weights):\n",
    "    forwarded_v = star.forward(poses, betas, trans)[0]\n",
    "    forwarded_v = torch.roll(forwarded_v, 1, 1) * 1000\n",
    "    return calc_loss(forwarded_v, betas, exclude_idx, min_comp_cosine, landmarks, E_weights)\n",
    "\n",
    "def constrain_poses(poses):\n",
    "    \"\"\"constrain some poses to not change, which maintain left-right symmetry\"\"\"\n",
    "    with torch.no_grad():\n",
    "        poses.grad[0, 2] = 0\n",
    "        poses.grad[0, 3*12+1] = 0\n",
    "        poses.grad[0, 3*12+2] = 0\n",
    "        poses.grad[0, 3*15+1] = 0\n",
    "        poses.grad[0, 3*15+2] = 0\n",
    "        \n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    loss = simple_loss(poses, betas, trans, min_comp_cosine=0, E_weights=(10, 1, 0))\n",
    "    loss.backward()\n",
    "    constrain_poses(poses)\n",
    "    return loss\n",
    "loss = optimizer.step(closure)\n",
    "    \n",
    "new_v = star.forward(poses, betas, trans).detach().numpy()[0]\n",
    "new_v = np.roll(new_v, 1, axis=1) * 1000\n",
    "fitted_mesh = trimesh.Trimesh(new_v, star.f, process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aebf2253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9423cb8c9a7848f6ad0f81472c0d44d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera=[999.7194918869128,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arrow_plot(fitted_mesh, target_mesh, inc_verts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0496c30",
   "metadata": {},
   "source": [
    "## Landmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b506a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('template_landmark_idxs.json') as fin:\n",
    "    template_lm_idxs = json.load(fin)\n",
    "    \"\"\n",
    "names_to_use = template_lm_idxs.keys()\n",
    "idxs_to_use = [template_lm_idxs[n] for n in names_to_use]\n",
    "template_lm_p = fitted_mesh.vertices[idxs_to_use]\n",
    "found_idx = target_mesh.kdtree.query(template_lm_p)[1]\n",
    "extracted_landmarks = {n: p for n, p in zip(names_to_use, target_mesh.vertices[found_idx])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b145244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark template vertex indices:\n",
      "{'crotch': 1353,\n",
      " 'crotch_like_tg3d': 1210,\n",
      " 'front_left_knee': 1047,\n",
      " 'front_right_knee': 4533,\n",
      " 'in_left_ankle': 3432,\n",
      " 'in_right_ankle': 6833,\n",
      " 'left_heel': 3426,\n",
      " 'navel': 3500,\n",
      " 'out_left_ankle': 3327,\n",
      " 'out_right_ankle': 6728,\n",
      " 'right_heel': 6825}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print('Landmark template vertex indices:')\n",
    "pprint(template_lm_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "111f4ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000d496ee6b5466789ca4fba74a28a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera=[860.2523919423708,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vedo.show(\n",
    "    tmesh(target_mesh),\n",
    "    vedo.Spheres(list(extracted_landmarks.values()), r=10),\n",
    "    viewup='z',\n",
    "    axes=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4c7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
